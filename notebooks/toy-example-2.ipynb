{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import elicito as el\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import copy\n",
    "\n",
    "tfd = tfp.distributions"
   ],
   "id": "6135c10dc3b61de7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class GenerativeModel:\n",
    "    def __call__(self, prior_samples, design_matrix, n_gr):\n",
    "        # extract prior samples per parameter type\n",
    "        betas=prior_samples[:,:,:-1]\n",
    "        sigma=prior_samples[:,:,-1][:,:,None]\n",
    "        # linear predictor\n",
    "        mu = tf.matmul(betas, design_matrix, transpose_b=True)\n",
    "        # data-generating model\n",
    "        y = tfd.Normal(loc=mu, scale=sigma).sample()\n",
    "        # selected observations per group\n",
    "        (y_gr0, y_gr1, y_gr2) = (y[:, :, i::] for i,j in zip(\n",
    "            [0,n_gr,2*n_gr],[n_gr,2*n_gr,-1]))\n",
    "        return dict(y_gr0=y_gr0, y_gr1=y_gr1,\n",
    "                    y_gr2=y_gr2, mu=mu, y=y)\n",
    "\n",
    "# design-matrix for three-level dummy-coded predictor\n",
    "def design_categorical(n_gr):\n",
    "    incpt = [1]*3\n",
    "    contrast_01 = [0, 1, 0]\n",
    "    contrast_02 = [0, 0, 1]\n",
    "    # contrast matrix\n",
    "    c = tf.stack([incpt, contrast_01, contrast_02], axis=-1)\n",
    "    # design matrix\n",
    "    x = tf.concat([tf.broadcast_to(c[i, :], (n_gr, c.shape[1])) for\n",
    "                   i in range(c.shape[0])], axis=0)\n",
    "    return tf.cast(x, tf.float32)\n",
    "\n",
    "model=el.model(\n",
    "    obj=GenerativeModel,\n",
    "    n_gr=30,\n",
    "    design_matrix=design_categorical(n_gr=30)\n",
    ")\n",
    "\n",
    "parameters=[\n",
    "    el.parameter(\n",
    "        name=f\"beta{i}\",\n",
    "        family=tfd.Normal,\n",
    "        hyperparams=dict(loc=el.hyper(f\"mu{i}\"),\n",
    "        scale=el.hyper(f\"sigma{i}\", lower=0))\n",
    "        ) for i in range(3)\n",
    "    ]+[\n",
    "    el.parameter(\n",
    "        name=\"sigma\",\n",
    "        family=tfd.HalfNormal,\n",
    "        hyperparams=dict(scale=el.hyper(\"sigma3\", lower=0))\n",
    "    ),\n",
    "]\n",
    "\n",
    "def r2(y, mu):\n",
    "    return tf.divide(\n",
    "        tf.math.reduce_variance(mu, axis=-1),\n",
    "        tf.math.reduce_variance(y, axis=-1)\n",
    "    )\n",
    "\n",
    "targets=[\n",
    "    el.target(\n",
    "        name=f\"y_gr{i}\",\n",
    "        query=el.queries.quantiles(quantiles=(.25, .50, .75)),\n",
    "        loss=el.losses.MMD2(kernel=\"energy\"),\n",
    "        ) for i in range(3)\n",
    "    ]+[\n",
    "    el.target(\n",
    "        name=\"r2\",\n",
    "        query=el.queries.quantiles(quantiles=(.25, .50, .75)),\n",
    "        loss=el.losses.MMD2(kernel=\"energy\"),\n",
    "        target_method=r2,\n",
    "        weight=10.\n",
    "    )\n",
    "]\n",
    "\n",
    "expert = el.expert.data(\n",
    "    dat={'quantiles_y_gr0': [0.64, 1.22, 1.89],\n",
    "        'quantiles_y_gr1': [0.72, 1.39, 2.07],\n",
    "        'quantiles_y_gr2': [0.76, 1.48, 2.22],\n",
    "        'quantiles_r2': [0.07, 0.23, 0.61]}\n",
    "    )\n",
    "\n",
    "optimizer=el.optimizer(\n",
    "    optimizer=tf.keras.optimizers.Adam,\n",
    "    learning_rate=0.05\n",
    ")\n",
    "\n",
    "trainer=el.trainer(\n",
    "    method=\"parametric_prior\",\n",
    "    seed=1234,\n",
    "    epochs=600,\n",
    "    progress=0\n",
    ")\n",
    "\n",
    "initializer=el.initializer(\n",
    "    method=\"sobol\",\n",
    "    iterations=32,\n",
    "    distribution=el.initialization.uniform(radius=2., mean=0.)\n",
    ")\n",
    "\n",
    "eliobj = el.Elicit(\n",
    "    model=model,\n",
    "    parameters=parameters,\n",
    "    targets=targets,\n",
    "    expert=expert,\n",
    "    optimizer=optimizer,\n",
    "    trainer=trainer,\n",
    "    initializer=initializer\n",
    ")\n"
   ],
   "id": "24de4f2b95408775"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "parameters_deep=[\n",
    "    el.parameter(name=f\"beta{i}\") for i in range(3)\n",
    "    ]+[\n",
    "    el.parameter(name=\"sigma\", lower=0),\n",
    "]\n",
    "\n",
    "targets_deep = targets + [\n",
    "    el.target(\n",
    "        name=\"cor\",\n",
    "        query=el.queries.correlation(),\n",
    "        loss=el.losses.L2,\n",
    "        weight=0.1\n",
    "    )\n",
    "]\n",
    "\n",
    "expert_deep = el.expert.data(\n",
    "    dat={'quantiles_y_gr0': [0.64, 1.22, 1.89],\n",
    "         'quantiles_y_gr1': [0.72, 1.39, 2.07],\n",
    "         'quantiles_y_gr2': [0.76, 1.48, 2.22],\n",
    "         'quantiles_r2': [0.07, 0.23, 0.61],\n",
    "         'cor_cor': [0.]*6\n",
    "         }\n",
    ")\n",
    "optimizer_deep=el.optimizer(\n",
    "    optimizer=tf.keras.optimizers.Adam,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "trainer_deep=el.trainer(\n",
    "    method=\"deep_prior\",\n",
    "    seed=2025,\n",
    "    # when you run the notebook online you might want to\n",
    "    # reduce the number of iterations as it is rather slow\n",
    "    epochs=800,\n",
    "    progress=1\n",
    ")\n",
    "\n",
    "network=el.networks.NF(\n",
    "    inference_network=el.networks.InvertibleNetwork,\n",
    "    network_specs=dict(\n",
    "        num_params=4,\n",
    "        num_coupling_layers=3,\n",
    "        coupling_design=\"affine\",\n",
    "        coupling_settings={\n",
    "            \"dropout\": False,\n",
    "            \"dense_args\": {\n",
    "                \"units\": 128,\n",
    "                \"activation\": \"relu\",\n",
    "                \"kernel_regularizer\": None,\n",
    "            },\n",
    "            \"num_dense\": 2,\n",
    "        },\n",
    "        permutation=\"fixed\"\n",
    "    ),\n",
    "    base_distribution=el.networks.base_normal\n",
    ")"
   ],
   "id": "216e0bbb81f9299e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# copy existing eliobj\n",
    "eliobj_deep = copy.deepcopy(eliobj)\n",
    "# update eliobj\n",
    "eliobj_deep.update(\n",
    "    parameters=parameters_deep,\n",
    "    targets=targets_deep,\n",
    "    expert=expert_deep,\n",
    "    optimizer=optimizer_deep,\n",
    "    trainer=trainer_deep,\n",
    "    initializer=None,\n",
    "    network=network\n",
    ")\n",
    "# fit updated eliobj\n",
    "eliobj_deep.fit()\n",
    "# run online only one chain as the parallel option might be\n",
    "# computationally to expensive and the notebook might crash\n",
    "# eliobj_deep.fit(parallel=el.utils.parallel(runs=5))"
   ],
   "id": "bc6e35f644c5143e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# eliobj_deep.save(file=\"saved_eliobj/eliobj_deep\")",
   "id": "5930b484e39f7b0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "el.plots.loss(eliobj_deep, figsize=(6,2))",
   "id": "213bb92f0ecb2f92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "el.plots.hyperparameter(eliobj_deep, figsize=(6,2))",
   "id": "65dbcb105155c654"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "el.plots.elicits(eliobj_deep, cols=5, figsize=(7,2))",
   "id": "8158065ae885e4a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "el.plots.prior_joint(eliobj_deep)",
   "id": "d11989fd7b2d1e86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "el.plots.prior_marginals(eliobj_deep, figsize=(6,2))",
   "id": "32a712feb7a3fac2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "el.plots.prior_averaging(eliobj_deep, figsize=(6,4), xlim_weights=0.5)",
   "id": "d59b5f6d6fc4b056"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
